{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "potential-polyester",
   "metadata": {},
   "source": [
    "# Large News Corpus Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "healthy-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "attractive-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('data/news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "moral-chocolate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news_09.txt',\n",
       " 'news_08.txt',\n",
       " 'news_18.txt',\n",
       " 'news_19.txt',\n",
       " 'news_03.txt',\n",
       " 'news_17.txt',\n",
       " 'news_16.txt',\n",
       " 'news_02.txt',\n",
       " 'news_14.txt',\n",
       " 'news_01.txt',\n",
       " 'news_15.txt',\n",
       " 'news_11.txt',\n",
       " 'news_05.txt',\n",
       " 'news_04.txt',\n",
       " 'news_10.txt',\n",
       " 'news_06.txt',\n",
       " 'news_12.txt',\n",
       " 'news_13.txt',\n",
       " 'news_07.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crucial-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elect-plate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_09.txt\n",
      "Start shape: (99934, 1)\n",
      "Ending shape: (76857, 1)\n",
      "\n",
      "\n",
      "news_08.txt\n",
      "Start shape: (99879, 1)\n",
      "Ending shape: (76783, 1)\n",
      "\n",
      "\n",
      "news_18.txt\n",
      "Start shape: (99995, 1)\n",
      "Ending shape: (77983, 1)\n",
      "\n",
      "\n",
      "news_19.txt\n",
      "Start shape: (59906, 1)\n",
      "Ending shape: (45004, 1)\n",
      "\n",
      "\n",
      "news_03.txt\n",
      "Start shape: (99917, 1)\n",
      "Ending shape: (72512, 1)\n",
      "\n",
      "\n",
      "news_17.txt\n",
      "Start shape: (99996, 1)\n",
      "Ending shape: (80741, 1)\n",
      "\n",
      "\n",
      "news_16.txt\n",
      "Start shape: (99990, 1)\n",
      "Ending shape: (79066, 1)\n",
      "\n",
      "\n",
      "news_02.txt\n",
      "Start shape: (99911, 1)\n",
      "Ending shape: (70717, 1)\n",
      "\n",
      "\n",
      "news_14.txt\n",
      "Start shape: (99961, 1)\n",
      "Ending shape: (79558, 1)\n",
      "\n",
      "\n",
      "news_01.txt\n",
      "Start shape: (99882, 1)\n",
      "Ending shape: (73875, 1)\n",
      "\n",
      "\n",
      "news_15.txt\n",
      "Start shape: (99966, 1)\n",
      "Ending shape: (79176, 1)\n",
      "\n",
      "\n",
      "news_11.txt\n",
      "Start shape: (99996, 1)\n",
      "Ending shape: (78985, 1)\n",
      "\n",
      "\n",
      "news_05.txt\n",
      "Start shape: (99808, 1)\n",
      "Ending shape: (71965, 1)\n",
      "\n",
      "\n",
      "news_04.txt\n",
      "Start shape: (99937, 1)\n",
      "Ending shape: (75953, 1)\n",
      "\n",
      "\n",
      "news_10.txt\n",
      "Start shape: (99844, 1)\n",
      "Ending shape: (74598, 1)\n",
      "\n",
      "\n",
      "news_06.txt\n",
      "Start shape: (99742, 1)\n",
      "Ending shape: (75072, 1)\n",
      "\n",
      "\n",
      "news_12.txt\n",
      "Start shape: (99991, 1)\n",
      "Ending shape: (78925, 1)\n",
      "\n",
      "\n",
      "news_13.txt\n",
      "Start shape: (99978, 1)\n",
      "Ending shape: (81071, 1)\n",
      "\n",
      "\n",
      "news_07.txt\n",
      "Start shape: (99637, 1)\n",
      "Ending shape: (74451, 1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(file)\n",
    "    df = pd.read_csv('data/news/'+file, header=None, index_col=False, sep=\"\\n\")\n",
    "    print(\"Start shape:\", df.shape)\n",
    "    df['len'] = [len(x.split()) for x in df[0].tolist()]\n",
    "    df = df[df['len'] > 100]\n",
    "    df = df.rename(columns={0:'text'})\n",
    "    df = df[['text']]\n",
    "    print(\"Ending shape:\", df.shape)\n",
    "    all_text = all_text.append(df, ignore_index=True)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acoustic-enclosure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Товчхон Сүүлийн жилүүдэд хөдөлмөрчид, ард иргэ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Товчхон Мэргэжлийн боловсрол сургалтын салбарт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Товчхон Эх хэлээ эрхэмлэн дээдлэх, бичиг соёлы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Товчхон 0Улс түмнүүдийн эв нэгдэл, найрамдал н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Товчхон \"Явуулын студи\" нэвтрүүлгийн энэ удааг...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Товчхон Сүүлийн жилүүдэд хөдөлмөрчид, ард иргэ...\n",
       "1  Товчхон Мэргэжлийн боловсрол сургалтын салбарт...\n",
       "2  Товчхон Эх хэлээ эрхэмлэн дээдлэх, бичиг соёлы...\n",
       "3  Товчхон 0Улс түмнүүдийн эв нэгдэл, найрамдал н...\n",
       "4  Товчхон \"Явуулын студи\" нэвтрүүлгийн энэ удааг..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "civil-polish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1423287</th>\n",
       "      <td>1 цаг 14 минутын өмнө Tweet Илгээх Хэвлэх УЛАА...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423288</th>\n",
       "      <td>1 цаг 5 минутын өмнө Манай улсын нэгэн адил би...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423289</th>\n",
       "      <td>1 цаг 15 минутын өмнө ХАВРЫН ЭХЭН ЦАГААН БАР С...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423290</th>\n",
       "      <td>1 цаг 24 минутын өмнө Өнөөдөр зүүн зүгийн нутг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423291</th>\n",
       "      <td>Малчид, тээвэрчид, ард иргэдэд зориулсан мэдээ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "1423287  1 цаг 14 минутын өмнө Tweet Илгээх Хэвлэх УЛАА...\n",
       "1423288  1 цаг 5 минутын өмнө Манай улсын нэгэн адил би...\n",
       "1423289  1 цаг 15 минутын өмнө ХАВРЫН ЭХЭН ЦАГААН БАР С...\n",
       "1423290  1 цаг 24 минутын өмнө Өнөөдөр зүүн зүгийн нутг...\n",
       "1423291  Малчид, тээвэрчид, ард иргэдэд зориулсан мэдээ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sealed-feeling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1423292, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "solar-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text['len'] = [len(x.split()) for x in all_text['text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "welsh-corner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564.832935"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text['len'].sum() / 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-cookbook",
   "metadata": {},
   "source": [
    "564 million words is A LOT. It's probable that this is big enough that a smaller dataset would perform well enough. The Wikitext-103 dataset is about 100 million word. I will cut this down to 40%, which should be around 220 million words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "automated-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text['filter'] = np.random.choice([0,1], size=len(all_text), p=[0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "black-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = all_text[all_text['filter'] == 1].drop(columns=['filter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "amended-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568734, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "boolean-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = [len(x.split()) for x in all_text['text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "exciting-norman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225.64644"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(length) / 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "conditional-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text.to_csv('data/news.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-figure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
